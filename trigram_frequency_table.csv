Trigram,2022,2021,2020,2019,2018
graph neural network,0.0016926729790466726,0.001582994120307553,0.0012339006194394464,0.0006049118845021575,0.0001523817816695601
deep neural network,0.0012247326674330874,0.001613972478826292,0.0018704084317727632,0.002235933558270938,0.0023945708548073733
deep reinforcement learning,0.001080306645330129,0.0011276122500820927,0.001255236076836094,0.001438346036482908,0.0013115717636558565
convolutional neural network,0.0010716410840039515,0.0016759291958637695,0.0019948652665865403,0.0026302464903908626,0.004174172376448307
multiple input multiple (output),0.0008896642961542238,0.0009634269499327769,0.0007360732801843384,0.0009006465835921012,0.0012190542533564808
generative adversarial network,0.0008347824077550997,0.0011369057576377142,0.0011450028802867484,0.001536924269512889,0.0016544307724123668
natural language processing,0.0007943431215662714,0.0009045680687471732,0.0006293959932011009,0.00037638961702356465,0.0003265323892919145
3d object detection,0.0004939369955921178,0.0003407619437061269,0.00030225231311917277,0.00022404143870450278,5.986427137018433e-05
bidirectional encoder representation (transformer),0.00048238291382388115,0.0007961438139315874,0.000874753753262547,0.0005825077406317072,1.088441297639715e-05
massive multiple input,0.000462163270729467,0.0005669039608929202,0.00046582415316013685,0.0005735460830835271,0.0007238134629304105
pre-trained language model,0.00045060918896123027,0.0003407619437061269,0.0001884632070037195,8.513574670771106e-05,1.088441297639715e-05
unmanned aerial vehicle,0.0004448321480771119,0.0004584797060773344,0.0004836037009906764,0.0006093927132762476,0.0006802758110248219
multi-agent reinforcement learning,0.00041594694365652027,0.00038103380978048737,0.0003378114087802519,0.00025540724012313316,0.00011972854274036866
simultaneous localization mapping,0.00040439286188828356,0.0003531532871136224,0.00030936413225138857,0.00027781138399358344,0.0003047635633391202
large language model,0.00040439286188828356,8.05437321487209e-05,3.555909566107915e-06,8.961657548180111e-06,0.0
spiking neural network,0.00039861582100416526,0.0003097835851873881,0.0003164759513836044,0.0002330030962526829,0.00012517074922856723
automatic speech recognition,0.0003957273005621061,0.0003035879134836403,0.00018135138787150364,0.0002598880688972232,0.00015782398815775869
named entity recognition,0.00038995025967798774,0.000312881421039262,0.0003520350470446836,0.00037638961702356465,0.0002394570854807373
deep learning model,0.00035239949393121856,0.0002911965700761448,0.0003413673183463598,0.00018819480851178233,0.0002231304660161416
neural machine translation,0.0003495109734891594,0.0004708710494848299,0.0006898464558249354,0.0008961657548180111,0.0009034062770409635
neural architecture search,0.00032351428951062685,0.00046157754192920823,0.0005298305253500793,0.0004211979047644652,0.0001306129557167658
graph convolutional network,0.00032351428951062685,0.00046467537778108214,0.0005333864349161872,0.0005332186241167167,0.0002231304660161416
machine learning model,0.0002975176055320944,0.00025092470400178436,0.00020268684526815114,0.00016579066464133207,8.163309732297862e-05
unsupervised domain adaptation,0.00028885204420591685,0.00038722948148423513,0.0002880286748547411,0.0002598880688972232,0.00015782398815775869
neural radiance field,0.0002830750033217985,0.00013630477748245075,3.5559095661079145e-05,0.0,0.0
offline reinforcement learning,0.0002772979624376802,0.00018896798696430673,5.689455305772664e-05,8.961657548180111e-06,0.0
3d point cloud,0.00027152092155356184,0.00020755500207555002,0.00023469003136312238,0.00021507978115632267,0.0001741506076223544
graphic processing unit,0.00026863240111150267,0.00026641388326115374,0.00030225231311917277,0.00028677304154176356,0.0002884369438745245
model predictive control,0.00025418979890120684,0.00018587015111243285,0.00013156865394599285,0.00022404143870450278,0.00029932135685092166
multiple output system,0.00025418979890120684,0.000312881421039262,0.0001742395687392878,0.00024644558257495304,0.0003047635633391202
visual question answering,0.00025130127845914767,0.00023233768889054107,0.0002666932174580936,0.00021956060993041273,0.0002666681179217302
recurrent neural network,0.00023397015580679264,0.00039652298903985675,0.0005760573497094822,0.0009006465835921012,0.0010721146781751192
medical image segmentation,0.00022530459448061514,0.0001951636586680545,0.0001209009252476691,0.00010753989057816133,9.795971678757435e-05
explainable artificial intelligence,0.00022241607403855596,0.00020135933037180226,0.00011378910611545328,7.169326038544089e-05,2.17688259527943e-05
physics-informed neural network,0.00022241607403855596,9.60329114080903e-05,6.045046262383455e-05,2.6884972644540334e-05,0.0
stochastic gradient descent,0.0002108619922703193,0.0002633160474092799,0.0003627027757430073,0.0003539854731531144,0.0002829947373863259
time series forecasting,0.00020797347182826013,0.00017038097185306344,0.00010312137741712952,6.721243161135083e-05,3.265323892919145e-05
human pose estimation,0.00020508495138620096,0.00021994634548304554,0.00023469003136312238,0.0002016372948340525,0.00016870840113415584
deep learning approach,0.00019353086961796428,0.0002106528379274239,0.0002418018504953382,0.00024196475380086301,0.00027755253089812736
markov decision process,0.00019353086961796428,0.00018587015111243285,0.00020979866440036697,0.00024644558257495304,0.000217688259527943
neural network training,0.00019064234917590513,0.00015179395674182016,0.0002133545739664749,0.00019715646605996244,0.00016326619464595725
graph representation learning,0.00018775382873384596,0.0001425004491861985,0.00014223638264431658,8.0654917933621e-05,4.8979858393787176e-05
systematic literature review,0.00018486530829178678,0.00015179395674182016,0.00012801274437988493,0.00010753989057816133,5.442206488198575e-05
channel state information,0.0001733112265235501,0.00010842425481558583,0.00013156865394599285,0.00010753989057816133,0.00016326619464595725
causal language interpretation (generation),0.0001733112265235501,7.744589629684702e-05,0.0,0.0,0.0
fake news detection,0.0001646456651973726,0.00013940261333432463,9.245364871880578e-05,8.961657548180112e-05,2.7211032440992876e-05
reinforcement learning approach,0.0001646456651973726,0.0001425004491861985,0.0001706836591731799,0.00012546320567452155,0.00014149736869316295
non-orthogonal multiple access,0.00015886862431325428,0.00025092470400178436,0.0003129200418174965,0.0003539854731531144,0.0005496628553080561
reconfigurable intelligent surface,0.00015886862431325428,0.00023853336059428883,0.00020979866440036697,6.273160283726078e-05,5.442206488198575e-06
salient object detection,0.0001559801038711951,0.0001610874642974418,0.00019557502613593532,0.00015682900709315195,0.00010340192327577293
natural language understanding,0.0001559801038711951,0.00017038097185306344,0.00015290411134264033,0.00012546320567452155,7.074868434658147e-05
pretrained language model,0.0001559801038711951,0.00015489179259369404,0.00010312137741712952,5.376994528908067e-05,0.0
monocular depth estimation,0.0001559801038711951,0.000130109105778703,0.0001209009252476691,0.0001299440344486116,0.00010340192327577293
partial differential equation,0.00015309158342913592,9.913074725996419e-05,7.46741008882662e-05,8.961657548180112e-05,5.442206488198575e-05
electronic health record,0.00015309158342913592,0.00013320694163057687,0.00015646002090874826,0.00017923315096360224,0.0001306129557167658
multivariate time series,0.00015020306298707675,0.00011152209066745971,0.00012445683481377703,4.480828774090056e-05,4.35376519055886e-05
ordinary differential equation,0.00015020306298707675,0.00012081559822308136,0.00011023319654934536,7.169326038544089e-05,5.442206488198575e-05
red green blue,0.0001473145425450176,0.0001796744794086851,0.0001493482017765324,0.0002509264113490431,0.00021224605303974444
remote sensing image,0.0001473145425450176,0.0001146199265193336,0.00011734501568156119,0.00011202071935225139,0.0001741506076223544
artificial neural network,0.00014442602210295842,0.0001920658228161806,0.00015290411134264033,0.0002105989523822326,0.00016326619464595725
object pose estimation,0.00014442602210295842,6.50545528893515e-05,8.178592002048204e-05,8.0654917933621e-05,7.619089083478005e-05
facial expression recognition,0.0001386489812188401,9.60329114080903e-05,0.00013512456351210075,8.513574670771106e-05,0.0001306129557167658
support vector machine,0.0001386489812188401,8.05437321487209e-05,0.0001920191165698274,0.00019267563728587238,0.00022857267250434016
long short-term memory,0.0001386489812188401,0.00025092470400178436,0.0003449232279124677,0.00043912121986082545,0.0005932005072136447
3d human pose,0.00013576046077678092,0.00016418530014931568,0.0001742395687392878,0.0001299440344486116,0.00014693957518136153
click-through rate prediction,0.00013287194033472175,0.00010222858311183807,8.889773915269787e-05,5.8250774063170725e-05,2.17688259527943e-05
machine learning approach,0.00012998341989266257,0.00013940261333432463,0.00015290411134264033,0.00017923315096360224,0.0001523817816695601
natural language inference,0.00012998341989266257,0.00011152209066745971,0.00013156865394599285,0.0001299440344486116,0.00013605516220496438
cell-free massive multiple,0.00012998341989266257,0.00017038097185306344,7.46741008882662e-05,8.0654917933621e-05,5.986427137018433e-05
human activity recognition,0.00012709489945060342,9.60329114080903e-05,0.00011734501568156119,0.00011650154812634145,0.00011972854274036866
natural language generation,0.00012709489945060342,0.00012391343407495522,0.00010667728698323745,0.00014786734954497184,7.074868434658147e-05
neural network inference,0.00012709489945060342,0.00010222858311183807,8.534182958658996e-05,0.00012098237690043151,9.251751029937578e-05
integrated sensing communication,0.00012420637900854424,3.717403022248657e-05,0.0,0.0,0.0
magnetic resonance imaging,0.00012420637900854424,0.00015489179259369404,0.0001742395687392878,0.00027781138399358344,0.0004789141709614746
neural network model,0.00012131785856648507,0.00020135933037180226,0.0002169104835325828,0.0001837139797376923,0.0002013616400633473
intrusion detection system,0.0001184293381244259,0.0001270112699268291,0.00010312137741712952,9.857823302998122e-05,0.00011972854274036866
graph contrastive learning,0.0001184293381244259,5.5761045333729856e-05,1.0667728698323745e-05,0.0,0.0
neural network accelerator,0.0001184293381244259,8.673940385246866e-05,7.823001045437413e-05,6.721243161135083e-05,6.53064778583829e-05
high performance computing,0.0001184293381244259,0.00017038097185306344,0.00018490729743761157,0.00017475232218951218,0.000179592814110553
application programming interface,0.00011265229724030757,0.00012391343407495522,0.00011734501568156119,0.00011650154812634145,0.00011428633625217008
scene graph generation,0.00011265229724030757,7.744589629684702e-05,4.9782733925510804e-05,1.7923315096360222e-05,2.7211032440992876e-05
video object segmentation,0.00011265229724030757,9.913074725996419e-05,0.00013512456351210075,0.00013442486322270167,0.00014149736869316295
speech emotion recognition,0.00011265229724030757,8.673940385246866e-05,5.689455305772664e-05,3.136580141863039e-05,8.163309732297862e-05
knowledge graph completion,0.00011265229724030757,5.5761045333729856e-05,8.178592002048204e-05,6.721243161135083e-05,2.17688259527943e-05
synthetic aperture radar,0.0001097637767982484,8.05437321487209e-05,6.756228175605038e-05,4.928911651499061e-05,6.53064778583829e-05
spoken language understanding,0.0001097637767982484,9.913074725996419e-05,0.00010312137741712952,9.857823302998122e-05,7.619089083478005e-05
field-programmable gate array,0.00010687525635618923,0.00011771776237120748,0.00019557502613593532,0.0001523481783190619,0.00018503502059875155
machine learning algorithm,0.00010687525635618923,7.434806044497314e-05,0.00012445683481377703,7.169326038544089e-05,4.35376519055886e-05
personalized federated learning,0.00010687525635618923,6.815238874122537e-05,2.844727652886332e-05,0.0,0.0
inverse reinforcement learning,0.00010398673591413007,9.60329114080903e-05,0.00010667728698323745,0.00012098237690043151,0.00011428633625217008
hate speech detection,0.00010109821547207089,0.00010842425481558583,7.111819132215829e-05,4.03274589668105e-05,2.7211032440992876e-05
deep convolutional neural,0.00010109821547207089,0.00015179395674182016,0.00023469003136312238,0.00031813884296039396,0.0005605472682844532
image quality assessment,9.820969503001173e-05,6.50545528893515e-05,4.622682435940289e-05,6.273160283726078e-05,3.8095445417390024e-05
monocular 3d object,9.820969503001173e-05,8.673940385246866e-05,3.200318609497123e-05,4.03274589668105e-05,1.6326619464595724e-05
language processing model,9.820969503001173e-05,8.05437321487209e-05,7.111819132215829e-05,2.6884972644540334e-05,1.088441297639715e-05
point cloud registration,9.532117458795257e-05,0.0001455982850380724,4.267091479329498e-05,4.03274589668105e-05,3.265323892919145e-05
neural ordinary differential,9.532117458795257e-05,9.293507555621643e-05,5.689455305772664e-05,2.240414387045028e-05,5.442206488198575e-06
radio access network,9.532117458795257e-05,9.293507555621643e-05,9.60095582849137e-05,0.00010753989057816133,0.0001306129557167658
model-based reinforcement learning,9.243265414589339e-05,0.00012081559822308136,0.0001457922922104245,8.961657548180112e-05,5.442206488198575e-05
video anomaly detection,9.243265414589339e-05,5.2663209481855975e-05,3.9115005227187065e-05,1.7923315096360222e-05,5.442206488198575e-06
